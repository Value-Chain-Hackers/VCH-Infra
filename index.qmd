---
title: "A.I Tools"
author: "C.G Verhoef"
format: revealjs
editor: visual
---

Installing the Local LLM stack onto Ixworks

<https://github.com/Value-Chain-Hackers/Ixworks-ai-packaged.git>

# üß≠ Project Overview: AI Sandbox Deployment

## üéØ Objective

To deploy a fully functional, self-hosted AI sandbox environment on the domain [`https://aisandbox1.ixworx.nl`](https://aisandbox1.ixworx.nl), utilizing Docker and HAProxy for secure, scalable, and modular access to various AI-related services. The aim is to enable internal research, testing, and demonstration of advanced tooling for the Value Chain Hackers initiative.

------------------------------------------------------------------------

## üß± Core Components

| Service | Purpose | Access Path |
|----------------|-------------------------------|-------------------------|
| n8n | No-code automation platform | `/n8n` |
| Open WebUI | LLM chat interface (backed by Ollama) | `/openwebui` |
| Flowise | Visual LLM workflow builder | `/flowise` |
| Supabase | Backend-as-a-service platform (auth, DB, storage) | `/supabase` |
| Langfuse | Observability for LLM applications | `/langfuse` (port 3002) |
| Qdrant | Vector database for embeddings | (API only, not exposed via subpath) |
| Ollama | Local LLM model server | `/ollama` |
| Redis (Valkey) | Caching and job queue | Internal use |
| MinIO | S3-compatible object storage | Internal use |
| ClickHouse | High-performance analytics DB (for Langfuse) | Internal use |
| SearXNG | Private, meta-search engine | `/searxng` |

------------------------------------------------------------------------

## üîê Networking & Routing

-   **TLS Termination**: Handled entirely by **HAProxy**, which routes HTTPS traffic to the internal server.
-   **Caddy**: Now redundant. It can be **removed** from the project.
-   **Subpath routing**: Each service is accessible through a distinct subpath on the main domain (`/n8n`, `/flowise`, etc.).
-   **Ports**: All services run on `localhost` and are **not exposed** to the internet directly. HAProxy maps external HTTPS paths to internal Docker ports.

------------------------------------------------------------------------

## üîÅ Deployment Strategy

-   All services are orchestrated with **Docker Compose**
-   Environment configuration is managed via a single **`.env`** file
-   The full stack is started via a custom **Python script (`start_services.py`)**
-   HAProxy is configured **externally** by Tommy and does not require modification on the server itself

------------------------------------------------------------------------

## üì¶ Deliverables

1.  A working `.env` file aligned with the domain and routing logic
2.  A functioning `docker-compose.yml` for all services
3.  Clean server environment with unnecessary Docker containers and Caddy removed
4.  Verified external access via [`https://aisandbox1.ixworx.nl/<service`](https://aisandbox1.ixworx.nl/<service)

------------------------------------------------------------------------

## üö¶Next Step

‚úÖ Finalize `.env`\
‚úÖ Confirm HAProxy mapping with Tommy\
üîÑ Run the stack using `python3 start_services.py`\
üß™ Smoke test all routes (`/n8n`, `/openwebui`, `/flowise`, etc.)

| Public Path | Server IP & Port | Comment |
|------------------------------|------------------|-----------------------|
| [`https://aisandbox1.ixworx.nl/n8n`](https://aisandbox1.ixworx.nl/n8n) | `95.99.112.224:5678` | n8n service |
| [`https://aisandbox1.ixworx.nl/openwebui`](https://aisandbox1.ixworx.nl/openwebui) | `95.99.112.224:3000` | Open WebUI |
| [`https://aisandbox1.ixworx.nl/flowise`](https://aisandbox1.ixworx.nl/flowise) | `95.99.112.224:3001` | Flowise service |
| [`https://aisandbox1.ixworx.nl/langfuse`](https://aisandbox1.ixworx.nl/langfuse) | `95.99.112.224:3002` | Langfuse |
| [`https://aisandbox1.ixworx.nl/ollama`](https://aisandbox1.ixworx.nl/ollama) | `95.99.112.224:11434` | Ollama API |
| [`https://aisandbox1.ixworx.nl/supabase`](https://aisandbox1.ixworx.nl/supabase) | `95.99.112.224:8000` | Supabase API Gateway (Kong) |
| [`https://aisandbox1.ixworx.nl/searxng`](https://aisandbox1.ixworx.nl/searxng) | `95.99.112.224:8080` | SearxNG search |

## Tools for possible intergration

| Tool Name | Function | GitHub Link | Status |
|------------------|------------------|------------------|------------------|
| ClickClickClick | GUI automation tool | [ClickClickClick](https://github.com/BandarLabs/clickclickclick) | Not Installed |
| Browser-Use WebUI | Browser automation and control | [Browser-Use WebUI](https://github.com/warmshao/browser-use) | Not Installed |
| smolagents | Lightweight agents for various tasks | [smolagents](https://github.com/huggingface/smolagents) | Not Installed |
| Hallo3 | Open-source generative AI model | [Hallo3](https://github.com/fudan-generative-vlp/hallo3) | Not Installed |
| XiaoZhi AI Chatbot | Lightweight chatbot on ESP32 | [XiaoZhi AI Chatbot](https://github.com/78/xiaozhi-esp32) | Not Installed |
| AIHawk | Job application assistant powered by AI | [AIHawk](https://github.com/feder-cr/Jobs_Applications_Hawk) | Not Installed |
| GPT Crawler | Automates crawling with GPT models | [GPT Crawler](https://github.com/BuilderIO/gpt-crawler) | Not Installed |
| Swarms | Multi-agent AI framework | [Swarms](https://github.com/kyegomez/swarms) | Not Installed |
| AI Hedge Fund | AI-powered hedge fund simulation | [AI Hedge Fund](https://github.com/virattt/ai-hedge-fund) | Not Installed |
| MiniMind | Open-source AI for mental health support | [MiniMind](https://github.com/jingyaogong/minimind) | Not Installed |

docker pull swarmscorp/swarms:latest\
<https://github.com/ianarawjo/ChainForge>

<https://big-agi.com/>

<https://github.com/Value-Chain-Hackers/VCH-self-hosted-ai-starter-kit.git>

volumes: n8n_storage: postgres_storage: ollama_storage: qdrant_storage:

networks: demo:

x-n8n: &service-n8n image: n8nio/n8n:latest networks: \['demo'\] environment: - DB_TYPE=postgresdb - DB_POSTGRESDB_HOST=postgres - DB_POSTGRESDB_USER=${POSTGRES_USER}
    - DB_POSTGRESDB_PASSWORD=${POSTGRES_PASSWORD} - N8N_DIAGNOSTICS_ENABLED=false - N8N_PERSONALIZATION_ENABLED=false - N8N_ENCRYPTION_KEY - N8N_USER_MANAGEMENT_JWT_SECRET links: - postgres

x-ollama: &service-ollama image: ollama/ollama:latest container_name: ollama networks: \['demo'\] restart: unless-stopped ports: - 11434:11434 volumes: - ollama_storage:/root/.ollama

x-init-ollama: &init-ollama image: ollama/ollama:latest networks: \['demo'\] container_name: ollama-pull-llama volumes: - ollama_storage:/root/.ollama entrypoint: /bin/sh command: - "-c" - "sleep 3; OLLAMA_HOST=ollama:11434 ollama pull llama3.2"

services: postgres: image: postgres:16-alpine networks: \['demo'\] restart: unless-stopped environment: - POSTGRES_USER - POSTGRES_PASSWORD - POSTGRES_DB volumes: - postgres_storage:/var/lib/postgresql/data healthcheck: test: \['CMD-SHELL', 'pg_isready -h localhost -U \${POSTGRES_USER} -d \${POSTGRES_DB}'\] interval: 5s timeout: 5s retries: 10

n8n-import: \<\<: \*service-n8n container_name: n8n-import entrypoint: /bin/sh command: - "-c" - "n8n import:credentials --separate --input=/backup/credentials && n8n import:workflow --separate --input=/backup/workflows" volumes: - ./n8n/backup:/backup depends_on: postgres: condition: service_healthy

n8n: \<\<: \*service-n8n container_name: n8n restart: unless-stopped ports: - 5678:5678 volumes: - n8n_storage:/home/node/.n8n - ./n8n/backup:/backup - ./shared:/data/shared depends_on: postgres: condition: service_healthy n8n-import: condition: service_completed_successfully

qdrant: image: qdrant/qdrant container_name: qdrant networks: \['demo'\] restart: unless-stopped ports: - 6333:6333 volumes: - qdrant_storage:/qdrant/storage

ollama-cpu: profiles: \["cpu"\] \<\<: \*service-ollama

ollama-gpu: profiles: \["gpu-nvidia"\] \<\<: \*service-ollama deploy: resources: reservations: devices: - driver: nvidia count: 1 capabilities: \[gpu\]

ollama-pull-llama-cpu: profiles: \["cpu"\] \<\<: \*init-ollama depends_on: - ollama-cpu

ollama-pull-llama-gpu: profiles: \["gpu-nvidia"\] \<\<: \*init-ollama depends_on: - ollama-gpu

smolagents: image: ghcr.io/huggingface/smolagents:latest container_name: smolagents networks: \['demo'\] ports: - "65432:65432" environment: - CONFIG_PATH=/app/config.yaml volumes: - ./smolagents/config:/app/config command: \> bash -c " echo Starting smolagents... && python3 -m smolagents"
